{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple REST service w/CRUD\n",
    "\n",
    "We will go over a small example REST service to highlight a couple of python features\n",
    "\n",
    "- Intro to pyproject.toml\n",
    "- Demo of getting existing data, creating new data, and showing existing data\n",
    "    - Show the code\n",
    "    - Start the service in reload mode\n",
    "    - Go to the swagger page\n",
    "    - Run example\n",
    "    - Run example with the httpx client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pyproject.toml file\n",
    "\n",
    "Python has started strongly leaning into the TOML file world over yaml. A TOML file will unambiguously map to...well, a\n",
    "map. The pyproject.toml has become standardized in [PEP-518](https://peps.python.org/pep-0518/) and is used by many\n",
    "python tooling like poetry, autopep8, pyflake, hatch, pipenv, and many others.\n",
    "\n",
    "We are using the poetry tool, and it has some important metadata extras.  \n",
    "\n",
    "- It does the work that would normally be done in a requirements.txt file\n",
    "    - the dependency resolver is more sophisticated than the default pip\n",
    "- replaces `setuptools.py` to build a wheel and upload to PyPI\n",
    "\n",
    "The pyproject.toml file's most import parts are:\n",
    "\n",
    "- The version of the project\n",
    "- The dependencies\n",
    "    - Dependencies can declare a range, or exact specifications\n",
    "    - Dependencies can be optional and installed with a `-E` extras flag\n",
    "    - Dependencies can also be installed in groups like for development with `-G dev`\n",
    "- Can specify alternative repositories (eg private repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a virtualenv and run \n",
    "!virtualenv -p python3.11.5 .venv\n",
    "!poetry install --with dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder on excursor\n",
    "\n",
    "If you have the latest excursor, you can use it to install \n",
    "\n",
    "- asdf\n",
    "- virtualenv\n",
    "- poetry\n",
    "\n",
    "It's been tested on fedora, amazonlinux and ubuntu.  Unfortunately, it's hard to test on a mac, because you can't truly\n",
    "start with a clean system like you can with linux docker containers\n",
    "\n",
    "```\n",
    "python -m excursor.core.installer full\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of ares: The code\n",
    "\n",
    "Show off a little demo of the beginnings of a roleplaying game engine.  It can create and retrieve characters from a\n",
    "local duckdb database.  duckdb is like sqlite on steroids.  Although it's meant for OLAP rather than OLTP apps, it has\n",
    "full ACID guarantees, so it can be used for OLTP also.\n",
    "\n",
    "- Show the initialization of the database\n",
    "- Show the functions in service.py\n",
    "- Show the model in db/characters/characters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import duckdb as dd\n",
    "from duckdb import DuckDBPyConnection\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import FileResponse\n",
    "import uvicorn\n",
    "\n",
    "from ares.models.character.character import Character, init_char_pq_path\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the database\n",
    "\n",
    "We use duckdb to store and query the data.  duckdb is extremely fast (faster than Spark by a wide margin on data that \n",
    "can fit on a single node).  Perhaps most interestingly, it can query JSON data that's been stored in a newline delimited\n",
    "format (eg NDJSON aka JSONL).\n",
    "\n",
    "Here, if we don't already have a database, it will be created.  Note the `init_df` variable which _looks_ like it is not\n",
    "being used.  But actually it is.  Duckdb will use the dataframe from the seeded initial parquet file (with the embedded\n",
    "schema) and be able to use it like SQL Table.\n",
    "\n",
    "> duckdb persistence\n",
    ">\n",
    "> By default, you do not have to give a name to connect, and it will use an in-memory database.  All data will be lost\n",
    "> when the program stops though\n",
    "\n",
    "If the db file does exist, then we load the `char_db` table.  A `testing` inner function will create a new random\n",
    "character each time we start up the service.  This is an example of a python inner function, which is handy when you\n",
    "want a _private_ function that is not accessible to outside code (technically, you can still get at it, but don't be a\n",
    "bad programmer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for databases\n",
    "ares_dir =Path(__file__).parent.parent\n",
    "\n",
    "# Create or open the database our service will use\n",
    "def init_db(db_name: str = \"ares.db\", test=True) -> DuckDBPyConnection:\n",
    "    if not Path(db_name).exists():\n",
    "        conn = dd.connect(db_name)\n",
    "        init_df = conn.read_parquet(f\"{init_char_pq_path}\")\n",
    "        conn.execute(\"CREATE TABLE char_db as SELECT * FROM init_df\")\n",
    "    else:\n",
    "        conn = dd.connect(db_name)\n",
    "        print(conn.sql(\"SHOW ALL TABLES\"))\n",
    "        print(conn.sql(\"SELECT * FROM char_db\"))\n",
    "\n",
    "\n",
    "    def new_record():\n",
    "        example = Character.random_character()\n",
    "        schema = Character.arrow_schema()\n",
    "        tbl = pa.Table.from_pylist([example.model_dump()], schema=schema)\n",
    "        sql_cmd = f\"INSERT INTO char_db SELECT * FROM tbl RETURNING *\"\n",
    "        print(sql_cmd)\n",
    "        df = conn.sql(sql_cmd)\n",
    "        print(df)\n",
    "\n",
    "    if test:\n",
    "        new_record()\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual REST methods\n",
    "\n",
    "This is how the actual methods are implemented.  I won't get into much detail other than this:\n",
    "\n",
    "- the route and http method are defined by the app.method and the route path\n",
    "- the parameters to a method are either query params, path params, or request body\n",
    "- get_parquet: saves the DB as parquet file and downloads to user\n",
    "- post_character: creates a new character and inserts into the db\n",
    "- get_character: gets a character by uuid\n",
    "- get_characters: returns a list of all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FastAPI application\n",
    "app = FastAPI()\n",
    "\n",
    "# /v1/characters\n",
    "char_ept = \"/v1/characters/\"\n",
    "\n",
    "# Create the database connection\n",
    "conn = init_db()\n",
    "\n",
    "@app.get(f\"{char_ept}parquet\")\n",
    "async def get_parquet():\n",
    "    df = conn.sql(\"SELECT * FROM char_db\")\n",
    "    pq_path = Path(\"parquet/saved.parquet\")\n",
    "    if pq_path.exists():\n",
    "        pq_path.unlink()\n",
    "    pq_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.write_parquet(\"parquet/saved.parquet\", compression=\"snappy\")\n",
    "    return FileResponse(pq_path)\n",
    "\n",
    "\n",
    "@app.post(char_ept)\n",
    "async def post_character(char: Character):\n",
    "    model = char.model_dump()\n",
    "    print(model)\n",
    "    schema = Character.arrow_schema()\n",
    "    tbl = pa.Table.from_pylist([model], schema=schema)\n",
    "    sql_cmd = f\"INSERT INTO char_db SELECT * FROM tbl RETURNING *\"\n",
    "    print(sql_cmd)\n",
    "    df = conn.sql(sql_cmd)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "@app.get(f\"{char_ept}/{{uid}}\")\n",
    "async def get_character(uid: str):\n",
    "    sql_cmd = f\"SELECT * FROM char_db WHERE uid = '{uid}'\"\n",
    "    df = conn.sql(sql_cmd)\n",
    "    batch = df.to_arrow_table()\n",
    "    data = batch.to_pylist()[0]\n",
    "    return data\n",
    "\n",
    "\n",
    "@app.get(char_ept)\n",
    "async def get_characters():\n",
    "    df = conn.sql(\"SELECT * FROM char_db\")\n",
    "    batch = df.to_arrow_table()\n",
    "    data = batch.to_pylist()\n",
    "    chars: list[Character] = []\n",
    "    for d in data:\n",
    "        d[\"skills\"] = {name: lvl for name, lvl in d[\"skills\"]}\n",
    "        chars.append(Character.model_validate(d))\n",
    "    return chars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Character model\n",
    "\n",
    "FastAPI makes heavy use of pydantic for data types that can be passed as request bodies, or returned as json responses. \n",
    "The important parts here are:\n",
    "\n",
    "- Helper functions `die` and `best_of`\n",
    "- Character which inherits from pydantic's `BaseModel`\n",
    "    - the fields must all be typed\n",
    "    - staticmethod to generate a random character\n",
    "    - arrow_schema which is used for duckdb and arrow/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from random import randint, random\n",
    "from uuid import uuid4\n",
    "\n",
    "import pyarrow as pa\n",
    "from pydantic import BaseModel\n",
    "init_char_pq_path = Path(__file__).parent.parent.parent / \"db/characters/character_init.parquet\"\n",
    "\n",
    "def die(num: int, size: int = 20):\n",
    "    def pool():\n",
    "        for _ in range(num):\n",
    "            yield randint(1, size)\n",
    "    return pool\n",
    "\n",
    "def best_of(pool: list[int], amount: int):\n",
    "    pool_size = len(pool)\n",
    "    if amount > pool_size:\n",
    "        amount = pool_size\n",
    "    start_from = pool_size - amount\n",
    "    return sorted(pool)[start_from:]\n",
    "\n",
    "class Character(BaseModel):\n",
    "    uid: str\n",
    "    player: str\n",
    "    player_id: str\n",
    "    force: int\n",
    "    speed: int\n",
    "    kinesthesia: int\n",
    "    wit: int\n",
    "    insight: int\n",
    "    discipline: int\n",
    "    height: float\n",
    "    weight: float\n",
    "    skills: dict[str, int]\n",
    "\n",
    "    @staticmethod\n",
    "    def random_character() -> \"Character\":\n",
    "        pool = die(4, 6)\n",
    "        return Character(\n",
    "            uid=str(uuid4()),\n",
    "            player=\"Sean Toner\",\n",
    "            player_id=str(uuid4()),\n",
    "            force=sum(best_of(list(pool()), 3)),\n",
    "            speed=sum(best_of(list(pool()), 3)),\n",
    "            kinesthesia=sum(best_of(list(pool()), 3)),\n",
    "            wit=sum(best_of(list(pool()), 3)),\n",
    "            insight=sum(best_of(list(pool()), 3)),\n",
    "            discipline=sum(best_of(list(pool()), 3)),\n",
    "            height=50.0 + random() * 50,\n",
    "            weight=60 + random() * 40,\n",
    "            skills={\n",
    "                \"1HSword\": sum(best_of(list(pool()), 3)),\n",
    "                \"Climbing\": sum(best_of(list(pool()), 3))\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def arrow_schema():\n",
    "        return pa.schema([\n",
    "            (\"uid\", pa.string()),\n",
    "            ('player', pa.string()),\n",
    "            (\"player_id\", pa.string()),\n",
    "            (\"force\", pa.int64()),\n",
    "            (\"speed\", pa.int64()),\n",
    "            (\"kinesthesia\", pa.int64()),\n",
    "            (\"wit\", pa.int64()),\n",
    "            (\"insight\", pa.int64()),\n",
    "            (\"discipline\", pa.int64()),\n",
    "            (\"height\", pa.float64()),\n",
    "            (\"weight\", pa.float64()),\n",
    "            (\"skills\", pa.map_(pa.string(), pa.int64()))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from ares.models.character.character import Character\n",
    "\n",
    "\n",
    "def test_add():\n",
    "    example = Character.random_character()\n",
    "    char = Character.model_validate(example)\n",
    "    resp = httpx.post(\"http://127.0.0.1:8000/v1/characters/\", json=char.model_dump())\n",
    "    print(resp)\n",
    "    print(resp.content)\n",
    "\n",
    "def test_list():\n",
    "    resp = httpx.get(\"http://127.0.0.1:8000/v1/characters/\")\n",
    "    print(resp.json())\n",
    "\n",
    "def test_by_id(uuid: str):\n",
    "    resp = httpx.get(f\"http://127.0.0.1:8000/v1/characters/{uuid}\")\n",
    "    print(resp)\n",
    "    print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_by_id(\"9ac41b52-5d63-4897-b168-0efc4868eb51\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
